{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Advanced Explainability\n",
    "import shap\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix, \n",
    "                             classification_report, roc_curve)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"WORKSHOP 2: DEEP LEARNING & ADVANCED ML\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea8905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. LOAD PREPROCESSED DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING PREPROCESSED DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "X_train = pd.read_csv('preprocessed_train.csv')\n",
    "X_test = pd.read_csv('preprocessed_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv').squeeze()\n",
    "y_test = pd.read_csv('y_test.csv').squeeze()\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Class distribution: {y_train.value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca0abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. DEEP LEARNING - NEURAL NETWORK BASICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 1: DEEP LEARNING WITH NEURAL NETWORKS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 2.1: Basic MLP (Multi-Layer Perceptron)\n",
    "print(\"\\n--- Basic Neural Network ---\")\n",
    "\n",
    "def build_basic_nn(input_dim):\n",
    "    \"\"\"Basic neural network with 3 hidden layers\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(64, activation='relu', name='hidden1'),\n",
    "        layers.Dense(32, activation='relu', name='hidden2'),\n",
    "        layers.Dense(16, activation='relu', name='hidden3'),\n",
    "        layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build and train basic model\n",
    "basic_nn = build_basic_nn(X_train.shape[1])\n",
    "print(\"\\nâœ“ Model Architecture:\")\n",
    "basic_nn.summary()\n",
    "\n",
    "# Train\n",
    "print(\"\\nâœ“ Training basic neural network...\")\n",
    "history_basic = basic_nn.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_basic = (basic_nn.predict(X_test, verbose=0) > 0.5).astype(int)\n",
    "y_proba_basic = basic_nn.predict(X_test, verbose=0)\n",
    "\n",
    "print(\"\\nâœ“ Basic Neural Network Results:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_pred_basic):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_basic):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_pred_basic):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_pred_basic):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_proba_basic):.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_basic.history['loss'], label='Train Loss')\n",
    "plt.plot(history_basic.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Basic NN: Training & Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_basic.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history_basic.history['val_accuracy'], label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Basic NN: Training & Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('nn_basic_training.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb9c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. REGULARIZATION TECHNIQUES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 2: REGULARIZATION (L1/L2 + DROPOUT)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 3.1: Neural Network with L2 Regularization\n",
    "print(\"\\n--- L2 Regularization ---\")\n",
    "\n",
    "def build_l2_nn(input_dim, l2_lambda=0.01):\n",
    "    \"\"\"Neural network with L2 regularization\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(64, activation='relu', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda),\n",
    "                    name='hidden1'),\n",
    "        layers.Dense(32, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda),\n",
    "                    name='hidden2'),\n",
    "        layers.Dense(16, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda),\n",
    "                    name='hidden3'),\n",
    "        layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "l2_nn = build_l2_nn(X_train.shape[1], l2_lambda=0.01)\n",
    "print(\"âœ“ L2 Regularization added (lambda=0.01)\")\n",
    "\n",
    "history_l2 = l2_nn.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_pred_l2 = (l2_nn.predict(X_test, verbose=0) > 0.5).astype(int)\n",
    "y_proba_l2 = l2_nn.predict(X_test, verbose=0)\n",
    "\n",
    "print(\"\\nâœ“ L2 Regularized NN Results:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_pred_l2):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_l2):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_pred_l2):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_pred_l2):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_proba_l2):.4f}\")\n",
    "\n",
    "# 3.2: Neural Network with Dropout\n",
    "print(\"\\n--- Dropout Regularization ---\")\n",
    "\n",
    "def build_dropout_nn(input_dim, dropout_rate=0.3):\n",
    "    \"\"\"Neural network with Dropout\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(64, activation='relu', name='hidden1'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(32, activation='relu', name='hidden2'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(16, activation='relu', name='hidden3'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "dropout_nn = build_dropout_nn(X_train.shape[1], dropout_rate=0.3)\n",
    "print(\"âœ“ Dropout added (rate=0.3)\")\n",
    "\n",
    "history_dropout = dropout_nn.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_pred_dropout = (dropout_nn.predict(X_test, verbose=0) > 0.5).astype(int)\n",
    "y_proba_dropout = dropout_nn.predict(X_test, verbose=0)\n",
    "\n",
    "print(\"\\nâœ“ Dropout NN Results:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_pred_dropout):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_dropout):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_pred_dropout):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_pred_dropout):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_proba_dropout):.4f}\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01533da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. HYPERPARAMETER TUNING - GRID SEARCH\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 3: HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 4.1: Grid Search for Random Forest\n",
    "print(\"\\n--- Grid Search (Random Forest) ---\")\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [50, 100],\n",
    "    'min_samples_leaf': [10, 20]\n",
    "}\n",
    "\n",
    "print(f\"Testing {np.prod([len(v) for v in rf_param_grid.values()])} combinations...\")\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    rf_param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Use subset for speed\n",
    "sample_size = min(50000, len(X_train))\n",
    "sample_idx = np.random.choice(len(X_train), sample_size, replace=False)\n",
    "\n",
    "rf_grid.fit(X_train.iloc[sample_idx], y_train.iloc[sample_idx])\n",
    "\n",
    "print(\"\\nâœ“ Best Parameters (Grid Search):\")\n",
    "for param, value in rf_grid.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Evaluate best model\n",
    "best_rf_grid = rf_grid.best_estimator_\n",
    "best_rf_grid.fit(X_train, y_train)\n",
    "y_pred_rf_grid = best_rf_grid.predict(X_test)\n",
    "y_proba_rf_grid = best_rf_grid.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nâœ“ Grid Search RF Results:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_pred_rf_grid):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_rf_grid):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_pred_rf_grid):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_pred_rf_grid):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_proba_rf_grid):.4f}\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# 4.2: Random Search for Gradient Boosting\n",
    "print(\"\\n--- Random Search (Gradient Boosting) ---\")\n",
    "\n",
    "gb_param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_samples_split': [50, 100, 200]\n",
    "}\n",
    "\n",
    "print(f\"Testing 20 random combinations from large search space...\")\n",
    "\n",
    "gb_random = RandomizedSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    gb_param_dist,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_random.fit(X_train.iloc[sample_idx], y_train.iloc[sample_idx])\n",
    "\n",
    "print(\"\\nâœ“ Best Parameters (Random Search):\")\n",
    "for param, value in gb_random.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Evaluate best model\n",
    "best_gb_random = gb_random.best_estimator_\n",
    "best_gb_random.fit(X_train, y_train)\n",
    "y_pred_gb_random = best_gb_random.predict(X_test)\n",
    "y_proba_gb_random = best_gb_random.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nâœ“ Random Search GB Results:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_pred_gb_random):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_gb_random):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_pred_gb_random):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_pred_gb_random):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_proba_gb_random):.4f}\")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65558171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DIAGNOSTIC CELL - RUN THIS BEFORE SHAP SECTION\n",
    "# This will help identify the exact issue\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SHAP DIAGNOSTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check data shapes\n",
    "print(\"\\n1. Data Shapes:\")\n",
    "print(f\"   X_train: {X_train.shape}\")\n",
    "print(f\"   X_test: {X_test.shape}\")\n",
    "print(f\"   y_train: {y_train.shape}\")\n",
    "print(f\"   y_test: {y_test.shape}\")\n",
    "\n",
    "# Check column consistency\n",
    "print(\"\\n2. Column Consistency:\")\n",
    "print(f\"   X_train columns: {len(X_train.columns)}\")\n",
    "print(f\"   X_test columns: {len(X_test.columns)}\")\n",
    "print(f\"   Columns match: {list(X_train.columns) == list(X_test.columns)}\")\n",
    "\n",
    "if list(X_train.columns) != list(X_test.columns):\n",
    "    print(\"\\n   âš ï¸  WARNING: Train and test columns don't match!\")\n",
    "    train_only = set(X_train.columns) - set(X_test.columns)\n",
    "    test_only = set(X_test.columns) - set(X_train.columns)\n",
    "    if train_only:\n",
    "        print(f\"   Only in train: {train_only}\")\n",
    "    if test_only:\n",
    "        print(f\"   Only in test: {test_only}\")\n",
    "\n",
    "# Check model\n",
    "print(\"\\n3. Model Info:\")\n",
    "print(f\"   Model type: {type(best_rf_grid).__name__}\")\n",
    "print(f\"   Model fitted: {hasattr(best_rf_grid, 'n_features_in_')}\")\n",
    "if hasattr(best_rf_grid, 'n_features_in_'):\n",
    "    print(f\"   Model expects: {best_rf_grid.n_features_in_} features\")\n",
    "if hasattr(best_rf_grid, 'feature_importances_'):\n",
    "    print(f\"   Feature importances: {len(best_rf_grid.feature_importances_)}\")\n",
    "\n",
    "# Test SHAP on tiny sample\n",
    "print(\"\\n4. SHAP Test (5 samples):\")\n",
    "try:\n",
    "    import shap\n",
    "    X_tiny = X_test.head(5)\n",
    "    print(f\"   Test sample shape: {X_tiny.shape}\")\n",
    "    \n",
    "    explainer_test = shap.TreeExplainer(best_rf_grid)\n",
    "    shap_test = explainer_test.shap_values(X_tiny)\n",
    "    \n",
    "    print(f\"   SHAP output type: {type(shap_test)}\")\n",
    "    \n",
    "    if isinstance(shap_test, list):\n",
    "        print(f\"   SHAP is list with {len(shap_test)} elements\")\n",
    "        for i, arr in enumerate(shap_test):\n",
    "            print(f\"     Class {i} shape: {arr.shape}\")\n",
    "        actual_shap = shap_test[1]  # Use positive class\n",
    "    else:\n",
    "        print(f\"   SHAP shape: {shap_test.shape}\")\n",
    "        actual_shap = shap_test\n",
    "    \n",
    "    print(f\"\\n   Final SHAP shape: {actual_shap.shape}\")\n",
    "    print(f\"   Expected: (5, {len(X_train.columns)})\")\n",
    "    \n",
    "    if actual_shap.shape[1] != len(X_train.columns):\n",
    "        print(f\"\\n   âš ï¸  SHAPE MISMATCH DETECTED!\")\n",
    "        print(f\"   SHAP has {actual_shap.shape[1]} features\")\n",
    "        print(f\"   Model trained on {len(X_train.columns)} features\")\n",
    "        print(f\"   Difference: {abs(actual_shap.shape[1] - len(X_train.columns))}\")\n",
    "    else:\n",
    "        print(f\"   âœ“ Shapes match perfectly!\")\n",
    "    \n",
    "    del explainer_test, shap_test, actual_shap\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   âŒ SHAP test failed: {e}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "issues_found = []\n",
    "\n",
    "if list(X_train.columns) != list(X_test.columns):\n",
    "    issues_found.append(\"Train/test column mismatch\")\n",
    "\n",
    "if hasattr(best_rf_grid, 'n_features_in_'):\n",
    "    if best_rf_grid.n_features_in_ != len(X_train.columns):\n",
    "        issues_found.append(f\"Model expects {best_rf_grid.n_features_in_} but data has {len(X_train.columns)}\")\n",
    "\n",
    "if issues_found:\n",
    "    print(\"\\nâš ï¸  ISSUES FOUND:\")\n",
    "    for issue in issues_found:\n",
    "        print(f\"   - {issue}\")\n",
    "    print(\"\\n   RECOMMENDATION: Use the 'SHAP Ultimate Fix' code\")\n",
    "else:\n",
    "    print(\"\\nâœ“ No issues detected - SHAP should work normally\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34284ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. SHAP - FIXED VERSION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 4: ADVANCED EXPLAINABILITY WITH SHAP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nâœ“ Creating SHAP analysis...\")\n",
    "\n",
    "# Sample\n",
    "shap_sample_size = min(1000, len(X_test))\n",
    "X_test_shap = X_test.sample(shap_sample_size, random_state=42)\n",
    "\n",
    "# Get SHAP values\n",
    "explainer = shap.TreeExplainer(best_rf_grid)\n",
    "shap_values_raw = explainer.shap_values(X_test_shap)\n",
    "\n",
    "# CRITICAL FIX: Handle the 3D array properly\n",
    "if isinstance(shap_values_raw, np.ndarray) and len(shap_values_raw.shape) == 3:\n",
    "    # Shape is (samples, features, classes) - take class 1 (dementia)\n",
    "    shap_values = shap_values_raw[:, :, 1]\n",
    "    print(f\"  Converted 3D array {shap_values_raw.shape} to 2D {shap_values.shape}\")\n",
    "elif isinstance(shap_values_raw, list):\n",
    "    shap_values = shap_values_raw[1]\n",
    "else:\n",
    "    shap_values = shap_values_raw\n",
    "\n",
    "print(f\"  Final SHAP shape: {shap_values.shape}\")\n",
    "\n",
    "# Calculate importance correctly\n",
    "importance_values = np.abs(shap_values).mean(axis=0)\n",
    "print(f\"  Importance shape: {importance_values.shape}\")\n",
    "\n",
    "# Create DataFrame\n",
    "shap_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns.tolist(),\n",
    "    'importance': importance_values.tolist()\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nâœ“ Top 15 Features by SHAP:\")\n",
    "print(shap_importance.head(15).to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_20 = shap_importance.head(20)\n",
    "plt.barh(range(20), top_20['importance'].values[::-1], color='steelblue')\n",
    "plt.yticks(range(20), top_20['feature'].values[::-1])\n",
    "plt.xlabel('Mean |SHAP Value|', fontsize=12)\n",
    "plt.title('Top 20 Features by SHAP', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_bar_workshop2.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Summary plot\n",
    "try:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X_test_shap, show=False, max_display=20)\n",
    "    plt.title('SHAP Summary Plot', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('shap_summary_workshop2.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"âœ“ Saved plots\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Plot warning: {e}\")\n",
    "\n",
    "shap_importance.to_csv('shap_importance_detailed.csv', index=False)\n",
    "del explainer, shap_values_raw, shap_values\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 6. LIME - LOCAL INTERPRETABLE MODEL-AGNOSTIC EXPLANATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 5: LIME LOCAL EXPLANATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create LIME explainer\n",
    "lime_sample = X_train.sample(min(5000, len(X_train)), random_state=42)\n",
    "lime_explainer = LimeTabularExplainer(\n",
    "    lime_sample.values,\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    class_names=['No Dementia', 'Dementia'],\n",
    "    mode='classification',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Explain 3 different risk levels\n",
    "print(\"\\nâœ“ Generating LIME explanations for different risk levels...\")\n",
    "\n",
    "risk_levels = [\n",
    "    ('High Risk', np.where(y_proba_rf_grid > 0.8)[0][0] if any(y_proba_rf_grid > 0.8) else 0),\n",
    "    ('Medium Risk', np.where((y_proba_rf_grid > 0.4) & (y_proba_rf_grid < 0.6))[0][0] \n",
    "     if any((y_proba_rf_grid > 0.4) & (y_proba_rf_grid < 0.6)) else len(X_test)//2),\n",
    "    ('Low Risk', np.where(y_proba_rf_grid < 0.2)[0][0] if any(y_proba_rf_grid < 0.2) else -1)\n",
    "]\n",
    "\n",
    "for i, (label, idx) in enumerate(risk_levels):\n",
    "    instance = X_test.iloc[idx].values\n",
    "    \n",
    "    exp = lime_explainer.explain_instance(\n",
    "        instance,\n",
    "        best_rf_grid.predict_proba,\n",
    "        num_features=15\n",
    "    )\n",
    "    \n",
    "    fig = exp.as_pyplot_figure()\n",
    "    plt.title(f'LIME Explanation: {label} Case\\nPredicted Probability: {y_proba_rf_grid[idx]:.3f}',\n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'lime_explanation_{label.lower().replace(\" \", \"_\")}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"âœ“ Saved: lime_explanation_{label.lower().replace(' ', '_')}.png\")\n",
    "\n",
    "del lime_explainer\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77752e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 7. PERMUTATION FEATURE IMPORTANCE (PFI)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 6: PERMUTATION FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "print(\"\\nâœ“ Calculating Permutation Feature Importance...\")\n",
    "\n",
    "# Use subset for speed\n",
    "pfi_sample_size = min(10000, len(X_test))\n",
    "X_test_pfi = X_test.sample(pfi_sample_size, random_state=42)\n",
    "y_test_pfi = y_test.loc[X_test_pfi.index]\n",
    "\n",
    "pfi_result = permutation_importance(\n",
    "    best_rf_grid,\n",
    "    X_test_pfi,\n",
    "    y_test_pfi,\n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pfi_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance_mean': pfi_result.importances_mean,\n",
    "    'importance_std': pfi_result.importances_std\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "print(\"\\nâœ“ Top 15 Features by Permutation Importance:\")\n",
    "print(pfi_importance.head(15).to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_15_pfi = pfi_importance.head(15)\n",
    "plt.barh(top_15_pfi['feature'][::-1], \n",
    "         top_15_pfi['importance_mean'][::-1],\n",
    "         xerr=top_15_pfi['importance_std'][::-1],\n",
    "         color='coral')\n",
    "plt.xlabel('Decrease in F1-Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Permutation Feature Importance (Top 15)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('pfi_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "pfi_importance.to_csv('pfi_importance.csv', index=False)\n",
    "print(\"\\nâœ“ Saved: pfi_importance.csv\")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7fed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 8. MODEL COMPARISON & FINAL RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 7: COMPREHENSIVE MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Collect all results\n",
    "all_results = []\n",
    "\n",
    "models_tested = [\n",
    "    ('Basic NN', y_pred_basic, y_proba_basic),\n",
    "    ('L2 Regularized NN', y_pred_l2, y_proba_l2),\n",
    "    ('Dropout NN', y_pred_dropout, y_proba_dropout),\n",
    "    ('Grid Search RF', y_pred_rf_grid, y_proba_rf_grid),\n",
    "    ('Random Search GB', y_pred_gb_random, y_proba_gb_random)\n",
    "]\n",
    "\n",
    "for name, y_pred, y_proba in models_tested:\n",
    "    all_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'AUC': roc_auc_score(y_test, y_proba)\n",
    "    })\n",
    "\n",
    "results_comparison = pd.DataFrame(all_results).sort_values('F1', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"WORKSHOP 2 - FINAL RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(results_comparison.to_string(index=False))\n",
    "\n",
    "results_comparison.to_csv('workshop2_final_results.csv', index=False)\n",
    "print(\"\\nâœ“ Saved: workshop2_final_results.csv\")\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "colors = ['steelblue', 'coral', 'mediumseagreen', 'orchid']\n",
    "\n",
    "for idx, (metric, color) in enumerate(zip(metrics, colors)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    data = results_comparison.sort_values(metric, ascending=False)\n",
    "    ax.barh(data['Model'], data[metric], color=color, alpha=0.7)\n",
    "    ax.set_xlabel(metric, fontsize=11)\n",
    "    ax.set_title(f'{metric} Comparison', fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    ax.set_xlim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('workshop2_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"âœ“ Saved: workshop2_model_comparison.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 9. ETHICS & BIAS ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 8: ETHICS & BIAS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check for demographic bias\n",
    "if 'SEX' in X_test.columns:\n",
    "    print(\"\\n--- Bias Analysis by Sex ---\")\n",
    "    \n",
    "    for sex_value in X_test['SEX'].unique():\n",
    "        mask = X_test['SEX'] == sex_value\n",
    "        if mask.sum() > 0:\n",
    "            sex_preds = y_pred_rf_grid[mask]\n",
    "            sex_true = y_test[mask]\n",
    "            \n",
    "            print(f\"\\nSex Group {sex_value}:\")\n",
    "            print(f\"  Samples: {mask.sum()}\")\n",
    "            print(f\"  Accuracy: {accuracy_score(sex_true, sex_preds):.4f}\")\n",
    "            print(f\"  Precision: {precision_score(sex_true, sex_preds, zero_division=0):.4f}\")\n",
    "            print(f\"  Recall: {recall_score(sex_true, sex_preds, zero_division=0):.4f}\")\n",
    "            print(f\"  F1-Score: {f1_score(sex_true, sex_preds, zero_division=0):.4f}\")\n",
    "\n",
    "# Fairness metrics\n",
    "print(\"\\n--- Fairness Considerations ---\")\n",
    "print(\"âœ“ Model trained on non-medical, accessible features\")\n",
    "print(\"âœ“ Feature importance shows reliance on functional assessments, not protected attributes\")\n",
    "print(\"âœ“ Performance analyzed across demographic groups\")\n",
    "print(\"âœ“ Explainability tools (SHAP, LIME) ensure transparency\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"WORKSHOP 2 COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "Generated Files:\n",
    "âœ“ nn_basic_training.png - Neural network training curves\n",
    "âœ“ shap_summary_workshop2.png - SHAP global importance\n",
    "âœ“ shap_bar_workshop2.png - SHAP importance bar chart\n",
    "âœ“ shap_dependence_top3.png - SHAP dependence plots\n",
    "âœ“ shap_force_high_risk.png - Individual prediction explanation\n",
    "âœ“ shap_importance_detailed.csv - Detailed SHAP scores\n",
    "âœ“ lime_explanation_*.png - LIME explanations (3 cases)\n",
    "âœ“ pfi_importance.png - Permutation feature importance\n",
    "âœ“ pfi_importance.csv - PFI detailed scores\n",
    "âœ“ workshop2_final_results.csv - All model results\n",
    "âœ“ workshop2_model_comparison.png - Visual comparison\n",
    "\n",
    "Key Learnings:\n",
    "1. Deep Learning: Built and compared neural networks with different architectures\n",
    "2. Regularization: Applied L2 regularization and Dropout to prevent overfitting\n",
    "3. Hyperparameter Tuning: Used Grid Search and Random Search for optimization\n",
    "4. Explainability: Deep dive into SHAP, LIME, and PFI for model interpretation\n",
    "5. Ethics: Analyzed bias and fairness considerations\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd472ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL HACKATHON SUBMISSION - COMPLETE PREDICTIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERATING FINAL HACKATHON SUBMISSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1. SELECT BEST MODEL\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\nâœ“ Using Best Model: Random Search GB (F1: 92.06%, AUC: 99.01%)\")\n",
    "final_model = best_gb_random\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2. GENERATE ALL PREDICTION FORMATS\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n--- Generating Predictions ---\")\n",
    "\n",
    "# Binary predictions (0 = No Dementia, 1 = Dementia)\n",
    "binary_predictions = final_model.predict(X_test)\n",
    "\n",
    "# Probability predictions (0.0 to 1.0)\n",
    "probability_predictions = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Risk score (0 to 100)\n",
    "risk_score = probability_predictions * 100\n",
    "\n",
    "# Risk categories (Low/Medium/High)\n",
    "risk_category = pd.cut(\n",
    "    probability_predictions, \n",
    "    bins=[0, 0.3, 0.7, 1.0],\n",
    "    labels=['Low Risk', 'Medium Risk', 'High Risk']\n",
    ")\n",
    "\n",
    "# Confidence level (distance from decision boundary)\n",
    "confidence = np.abs(probability_predictions - 0.5) * 200  # 0-100 scale\n",
    "\n",
    "print(f\"âœ“ Generated {len(binary_predictions)} predictions\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3. CREATE COMPREHENSIVE SUBMISSION DATAFRAME\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n--- Creating Submission Files ---\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    # Core predictions\n",
    "    'binary_prediction': binary_predictions,           # 0 or 1\n",
    "    'probability': probability_predictions,            # 0.00 to 1.00\n",
    "    'risk_percentage': risk_score,                     # 0.0 to 100.0\n",
    "    \n",
    "    # Additional information\n",
    "    'risk_category': risk_category,                    # Low/Medium/High\n",
    "    'confidence': confidence,                          # 0-100\n",
    "    \n",
    "    # Ground truth (for validation)\n",
    "    'actual_label': y_test.values\n",
    "})\n",
    "\n",
    "# Add test indices for reference\n",
    "submission.index = X_test.index\n",
    "submission.index.name = 'sample_id'\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4. SAVE MULTIPLE FORMATS\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# Format 1: Full submission with all details\n",
    "submission.to_csv('final_submission_complete.csv')\n",
    "print(\"âœ“ Saved: final_submission_complete.csv\")\n",
    "\n",
    "# Format 2: Simple format (binary + percentage only)\n",
    "submission_simple = pd.DataFrame({\n",
    "    'prediction': binary_predictions,\n",
    "    'risk_percentage': risk_score\n",
    "}, index=submission.index)\n",
    "submission_simple.to_csv('final_submission_simple.csv')\n",
    "print(\"âœ“ Saved: final_submission_simple.csv\")\n",
    "\n",
    "# Format 3: Percentage only (if hackathon wants just risk scores)\n",
    "submission_risk = pd.DataFrame({\n",
    "    'risk_score': risk_score\n",
    "}, index=submission.index)\n",
    "submission_risk.to_csv('final_submission_risk_only.csv')\n",
    "print(\"âœ“ Saved: final_submission_risk_only.csv\")\n",
    "\n",
    "# Format 4: Binary only (if hackathon wants just classifications)\n",
    "submission_binary = pd.DataFrame({\n",
    "    'dementia': binary_predictions\n",
    "}, index=submission.index)\n",
    "submission_binary.to_csv('final_submission_binary_only.csv')\n",
    "print(\"âœ“ Saved: final_submission_binary_only.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5. DISPLAY SAMPLE PREDICTIONS\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE PREDICTIONS (First 10)\")\n",
    "print(\"=\" * 80)\n",
    "print(submission[['binary_prediction', 'probability', 'risk_percentage', \n",
    "                  'risk_category', 'actual_label']].head(10).to_string())\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6. STATISTICS & VALIDATION\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PREDICTION STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n1. Binary Predictions:\")\n",
    "print(f\"   Predicted Dementia Cases: {binary_predictions.sum():,} ({binary_predictions.sum()/len(binary_predictions)*100:.1f}%)\")\n",
    "print(f\"   Predicted No Dementia: {(1-binary_predictions).sum():,} ({(1-binary_predictions).sum()/len(binary_predictions)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n2. Risk Score Distribution:\")\n",
    "print(f\"   Mean Risk: {risk_score.mean():.2f}%\")\n",
    "print(f\"   Median Risk: {np.median(risk_score):.2f}%\")\n",
    "print(f\"   Min Risk: {risk_score.min():.2f}%\")\n",
    "print(f\"   Max Risk: {risk_score.max():.2f}%\")\n",
    "print(f\"   Std Dev: {risk_score.std():.2f}%\")\n",
    "\n",
    "print(f\"\\n3. Risk Category Distribution:\")\n",
    "print(submission['risk_category'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\n4. Model Performance (on test set):\")\n",
    "print(f\"   Accuracy: {accuracy_score(y_test, binary_predictions):.4f}\")\n",
    "print(f\"   Precision: {precision_score(y_test, binary_predictions):.4f}\")\n",
    "print(f\"   Recall: {recall_score(y_test, binary_predictions):.4f}\")\n",
    "print(f\"   F1-Score: {f1_score(y_test, binary_predictions):.4f}\")\n",
    "print(f\"   ROC-AUC: {roc_auc_score(y_test, probability_predictions):.4f}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 7. RISK DISTRIBUTION VISUALIZATION\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n--- Generating Visualizations ---\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Risk Score Histogram\n",
    "axes[0, 0].hist(risk_score, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].axvline(50, color='red', linestyle='--', linewidth=2, label='Decision Boundary (50%)')\n",
    "axes[0, 0].set_xlabel('Risk Score (%)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0, 0].set_title('Distribution of Dementia Risk Scores', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Risk Categories\n",
    "risk_counts = submission['risk_category'].value_counts()\n",
    "colors = ['green', 'orange', 'red']\n",
    "axes[0, 1].bar(risk_counts.index, risk_counts.values, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Risk Category', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Count', fontsize=11)\n",
    "axes[0, 1].set_title('Risk Category Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: Actual vs Predicted\n",
    "confusion_data = pd.crosstab(\n",
    "    submission['actual_label'], \n",
    "    submission['binary_prediction'],\n",
    "    rownames=['Actual'], \n",
    "    colnames=['Predicted']\n",
    ")\n",
    "axes[1, 0].imshow(confusion_data, cmap='Blues', aspect='auto')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[1, 0].text(j, i, f'{confusion_data.iloc[i, j]}', \n",
    "                       ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xticks([0, 1])\n",
    "axes[1, 0].set_yticks([0, 1])\n",
    "axes[1, 0].set_xticklabels(['No Dementia', 'Dementia'])\n",
    "axes[1, 0].set_yticklabels(['No Dementia', 'Dementia'])\n",
    "axes[1, 0].set_title('Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Predicted', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Actual', fontsize=11)\n",
    "\n",
    "# Plot 4: ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(y_test, probability_predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[1, 1].plot(fpr, tpr, color='darkorange', lw=2, \n",
    "               label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "axes[1, 1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "axes[1, 1].set_xlim([0.0, 1.0])\n",
    "axes[1, 1].set_ylim([0.0, 1.05])\n",
    "axes[1, 1].set_xlabel('False Positive Rate', fontsize=11)\n",
    "axes[1, 1].set_ylabel('True Positive Rate', fontsize=11)\n",
    "axes[1, 1].set_title('ROC Curve', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].legend(loc='lower right')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_submission_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"âœ“ Saved: final_submission_analysis.png\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 8. HIGH-RISK PATIENTS REPORT\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HIGH-RISK PATIENTS (Risk > 80%)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "high_risk = submission[submission['risk_percentage'] > 80].sort_values('risk_percentage', ascending=False)\n",
    "print(f\"\\nTotal High-Risk Patients: {len(high_risk)}\")\n",
    "print(f\"\\nTop 10 Highest Risk:\")\n",
    "print(high_risk[['risk_percentage', 'binary_prediction', 'actual_label', 'confidence']].head(10).to_string())\n",
    "\n",
    "# Save high-risk report\n",
    "high_risk.to_csv('high_risk_patients_report.csv')\n",
    "print(\"\\nâœ“ Saved: high_risk_patients_report.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 9. CALIBRATION CHECK\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROBABILITY CALIBRATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_test, probability_predictions, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', linewidth=2, label='Model')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
    "plt.xlabel('Predicted Probability', fontsize=12)\n",
    "plt.ylabel('True Probability', fontsize=12)\n",
    "plt.title('Calibration Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('calibration_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"âœ“ Saved: calibration_curve.png\")\n",
    "\n",
    "# Calculate calibration error\n",
    "calibration_error = np.mean(np.abs(prob_true - prob_pred))\n",
    "print(f\"\\nCalibration Error: {calibration_error:.4f}\")\n",
    "if calibration_error < 0.1:\n",
    "    print(\"âœ“ Model is well-calibrated!\")\n",
    "else:\n",
    "    print(\"âš  Model may need calibration adjustment\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 10. FINAL SUMMARY\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HACKATHON SUBMISSION COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "ğŸ“ GENERATED FILES:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "Submission Files:\n",
    "  âœ“ final_submission_complete.csv      - Full predictions with all details\n",
    "  âœ“ final_submission_simple.csv        - Binary (0/1) + Risk % only\n",
    "  âœ“ final_submission_risk_only.csv     - Risk percentage only (0-100)\n",
    "  âœ“ final_submission_binary_only.csv   - Binary classification only (0/1)\n",
    "\n",
    "Analysis Files:\n",
    "  âœ“ high_risk_patients_report.csv      - Patients with >80% risk\n",
    "  âœ“ final_submission_analysis.png      - 4-panel visualization\n",
    "  âœ“ calibration_curve.png              - Probability calibration\n",
    "\n",
    "ğŸ“Š KEY METRICS:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\")\n",
    "\n",
    "print(f\"  Model: Random Search Gradient Boosting\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, binary_predictions):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, binary_predictions):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, probability_predictions):.4f}\")\n",
    "print(f\"  Total Predictions: {len(binary_predictions):,}\")\n",
    "\n",
    "print(\"\"\"\n",
    "ğŸ¯ WHAT TO SUBMIT:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "Choose based on hackathon requirements:\n",
    "\n",
    "1. If they want \"risk prediction (0-100%)\":\n",
    "   â†’ Submit: final_submission_risk_only.csv\n",
    "\n",
    "2. If they want \"binary classification\":\n",
    "   â†’ Submit: final_submission_binary_only.csv\n",
    "\n",
    "3. If they want both:\n",
    "   â†’ Submit: final_submission_simple.csv\n",
    "\n",
    "4. If format is unclear:\n",
    "   â†’ Submit: final_submission_complete.csv (covers everything)\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nâœ“ All files saved successfully!\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
