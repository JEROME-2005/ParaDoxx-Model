{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf01e94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "WORKSHOP 2: DEEP LEARNING & ADVANCED ML\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Advanced Explainability\n",
    "import shap\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix, \n",
    "                             classification_report, roc_curve)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"WORKSHOP 2: DEEP LEARNING & ADVANCED ML\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ea8905c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOADING PREPROCESSED DATA\n",
      "================================================================================\n",
      "Train: (156156, 98), Test: (39040, 98)\n",
      "Class distribution: {0: 0.704961704961705, 1: 0.29503829503829504}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. LOAD PREPROCESSED DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING PREPROCESSED DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "X_train = pd.read_csv('preprocessed_train.csv')\n",
    "X_test = pd.read_csv('preprocessed_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv').squeeze()\n",
    "y_test = pd.read_csv('y_test.csv').squeeze()\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Class distribution: {y_train.value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baca0abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 1: DEEP LEARNING WITH NEURAL NETWORKS\n",
      "================================================================================\n",
      "\n",
      "--- Basic Neural Network ---\n",
      "\n",
      "✓ Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,961</span> (35.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,961\u001b[0m (35.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,961</span> (35.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,961\u001b[0m (35.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Training basic neural network...\n",
      "\n",
      "✓ Basic Neural Network Results:\n",
      "  Accuracy:  0.9501\n",
      "  Precision: 0.9310\n",
      "  Recall:    0.8972\n",
      "  F1-Score:  0.9138\n",
      "  ROC-AUC:   0.9882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24951"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. DEEP LEARNING - NEURAL NETWORK BASICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 1: DEEP LEARNING WITH NEURAL NETWORKS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 2.1: Basic MLP (Multi-Layer Perceptron)\n",
    "print(\"\\n--- Basic Neural Network ---\")\n",
    "\n",
    "def build_basic_nn(input_dim):\n",
    "    \"\"\"Basic neural network with 3 hidden layers\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(64, activation='relu', name='hidden1'),\n",
    "        layers.Dense(32, activation='relu', name='hidden2'),\n",
    "        layers.Dense(16, activation='relu', name='hidden3'),\n",
    "        layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build and train basic model\n",
    "basic_nn = build_basic_nn(X_train.shape[1])\n",
    "print(\"\\n✓ Model Architecture:\")\n",
    "basic_nn.summary()\n",
    "\n",
    "# Train\n",
    "print(\"\\n✓ Training basic neural network...\")\n",
    "history_basic = basic_nn.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_basic = (basic_nn.predict(X_test, verbose=0) > 0.5).astype(int)\n",
    "y_proba_basic = basic_nn.predict(X_test, verbose=0)\n",
    "\n",
    "print(\"\\n✓ Basic Neural Network Results:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_pred_basic):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_basic):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_pred_basic):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_pred_basic):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_proba_basic):.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_basic.history['loss'], label='Train Loss')\n",
    "plt.plot(history_basic.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Basic NN: Training & Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_basic.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history_basic.history['val_accuracy'], label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Basic NN: Training & Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('nn_basic_training.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cb9c510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 2: REGULARIZATION (L1/L2 + DROPOUT)\n",
      "================================================================================\n",
      "\n",
      "--- L2 Regularization ---\n",
      "✓ L2 Regularization added (lambda=0.01)\n",
      "\n",
      "✓ L2 Regularized NN Results:\n",
      "  Accuracy:  0.9501\n",
      "  Precision: 0.9266\n",
      "  Recall:    0.9022\n",
      "  F1-Score:  0.9143\n",
      "  ROC-AUC:   0.9877\n",
      "\n",
      "--- Dropout Regularization ---\n",
      "✓ Dropout added (rate=0.3)\n",
      "\n",
      "✓ Dropout NN Results:\n",
      "  Accuracy:  0.9511\n",
      "  Precision: 0.9314\n",
      "  Recall:    0.9007\n",
      "  F1-Score:  0.9158\n",
      "  ROC-AUC:   0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. REGULARIZATION TECHNIQUES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 2: REGULARIZATION (L1/L2 + DROPOUT)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 3.1: Neural Network with L2 Regularization\n",
    "print(\"\\n--- L2 Regularization ---\")\n",
    "\n",
    "def build_l2_nn(input_dim, l2_lambda=0.01):\n",
    "    \"\"\"Neural network with L2 regularization\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(64, activation='relu', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda),\n",
    "                    name='hidden1'),\n",
    "        layers.Dense(32, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda),\n",
    "                    name='hidden2'),\n",
    "        layers.Dense(16, activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda),\n",
    "                    name='hidden3'),\n",
    "        layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "l2_nn = build_l2_nn(X_train.shape[1], l2_lambda=0.01)\n",
    "print(\"✓ L2 Regularization added (lambda=0.01)\")\n",
    "\n",
    "history_l2 = l2_nn.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_pred_l2 = (l2_nn.predict(X_test, verbose=0) > 0.5).astype(int)\n",
    "y_proba_l2 = l2_nn.predict(X_test, verbose=0)\n",
    "\n",
    "print(\"\\n✓ L2 Regularized NN Results:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_pred_l2):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_l2):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_pred_l2):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_pred_l2):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_proba_l2):.4f}\")\n",
    "\n",
    "# 3.2: Neural Network with Dropout\n",
    "print(\"\\n--- Dropout Regularization ---\")\n",
    "\n",
    "def build_dropout_nn(input_dim, dropout_rate=0.3):\n",
    "    \"\"\"Neural network with Dropout\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(64, activation='relu', name='hidden1'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(32, activation='relu', name='hidden2'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(16, activation='relu', name='hidden3'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "dropout_nn = build_dropout_nn(X_train.shape[1], dropout_rate=0.3)\n",
    "print(\"✓ Dropout added (rate=0.3)\")\n",
    "\n",
    "history_dropout = dropout_nn.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_pred_dropout = (dropout_nn.predict(X_test, verbose=0) > 0.5).astype(int)\n",
    "y_proba_dropout = dropout_nn.predict(X_test, verbose=0)\n",
    "\n",
    "print(\"\\n✓ Dropout NN Results:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_pred_dropout):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_dropout):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_pred_dropout):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_pred_dropout):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_proba_dropout):.4f}\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c01533da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 3: HYPERPARAMETER TUNING\n",
      "================================================================================\n",
      "\n",
      "--- Grid Search (Random Forest) ---\n",
      "Testing 24 combinations...\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "\n",
      "✓ Best Parameters (Grid Search):\n",
      "  max_depth: 15\n",
      "  min_samples_leaf: 10\n",
      "  min_samples_split: 50\n",
      "  n_estimators: 100\n",
      "\n",
      "✓ Grid Search RF Results:\n",
      "  Accuracy:  0.9502\n",
      "  Precision: 0.9325\n",
      "  Recall:    0.8962\n",
      "  F1-Score:  0.9140\n",
      "  ROC-AUC:   0.9890\n",
      "\n",
      "--- Random Search (Gradient Boosting) ---\n",
      "Testing 20 random combinations from large search space...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "✓ Best Parameters (Random Search):\n",
      "  subsample: 0.6\n",
      "  n_estimators: 200\n",
      "  min_samples_split: 50\n",
      "  max_depth: 3\n",
      "  learning_rate: 0.05\n",
      "\n",
      "✓ Random Search GB Results:\n",
      "  Accuracy:  0.9517\n",
      "  Precision: 0.9266\n",
      "  Recall:    0.9084\n",
      "  F1-Score:  0.9174\n",
      "  ROC-AUC:   0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. HYPERPARAMETER TUNING - GRID SEARCH\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 3: HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 4.1: Grid Search for Random Forest\n",
    "print(\"\\n--- Grid Search (Random Forest) ---\")\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [50, 100],\n",
    "    'min_samples_leaf': [10, 20]\n",
    "}\n",
    "\n",
    "print(f\"Testing {np.prod([len(v) for v in rf_param_grid.values()])} combinations...\")\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    rf_param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Use subset for speed\n",
    "sample_size = min(50000, len(X_train))\n",
    "sample_idx = np.random.choice(len(X_train), sample_size, replace=False)\n",
    "\n",
    "rf_grid.fit(X_train.iloc[sample_idx], y_train.iloc[sample_idx])\n",
    "\n",
    "print(\"\\n✓ Best Parameters (Grid Search):\")\n",
    "for param, value in rf_grid.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Evaluate best model\n",
    "best_rf_grid = rf_grid.best_estimator_\n",
    "best_rf_grid.fit(X_train, y_train)\n",
    "y_pred_rf_grid = best_rf_grid.predict(X_test)\n",
    "y_proba_rf_grid = best_rf_grid.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n✓ Grid Search RF Results:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_pred_rf_grid):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_rf_grid):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_pred_rf_grid):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_pred_rf_grid):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_proba_rf_grid):.4f}\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# 4.2: Random Search for Gradient Boosting\n",
    "print(\"\\n--- Random Search (Gradient Boosting) ---\")\n",
    "\n",
    "gb_param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_samples_split': [50, 100, 200]\n",
    "}\n",
    "\n",
    "print(f\"Testing 20 random combinations from large search space...\")\n",
    "\n",
    "gb_random = RandomizedSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    gb_param_dist,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_random.fit(X_train.iloc[sample_idx], y_train.iloc[sample_idx])\n",
    "\n",
    "print(\"\\n✓ Best Parameters (Random Search):\")\n",
    "for param, value in gb_random.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Evaluate best model\n",
    "best_gb_random = gb_random.best_estimator_\n",
    "best_gb_random.fit(X_train, y_train)\n",
    "y_pred_gb_random = best_gb_random.predict(X_test)\n",
    "y_proba_gb_random = best_gb_random.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n✓ Random Search GB Results:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_pred_gb_random):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_gb_random):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_pred_gb_random):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_pred_gb_random):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_proba_gb_random):.4f}\")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65558171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SHAP DIAGNOSTICS\n",
      "================================================================================\n",
      "\n",
      "1. Data Shapes:\n",
      "   X_train: (156156, 98)\n",
      "   X_test: (39040, 98)\n",
      "   y_train: (156156,)\n",
      "   y_test: (39040,)\n",
      "\n",
      "2. Column Consistency:\n",
      "   X_train columns: 98\n",
      "   X_test columns: 98\n",
      "   Columns match: True\n",
      "\n",
      "3. Model Info:\n",
      "   Model type: RandomForestClassifier\n",
      "   Model fitted: True\n",
      "   Model expects: 98 features\n",
      "   Feature importances: 98\n",
      "\n",
      "4. SHAP Test (5 samples):\n",
      "   Test sample shape: (5, 98)\n",
      "   SHAP output type: <class 'numpy.ndarray'>\n",
      "   SHAP shape: (5, 98, 2)\n",
      "\n",
      "   Final SHAP shape: (5, 98, 2)\n",
      "   Expected: (5, 98)\n",
      "   ✓ Shapes match perfectly!\n",
      "\n",
      "================================================================================\n",
      "DIAGNOSTIC SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✓ No issues detected - SHAP should work normally\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DIAGNOSTIC CELL - RUN THIS BEFORE SHAP SECTION\n",
    "# This will help identify the exact issue\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SHAP DIAGNOSTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check data shapes\n",
    "print(\"\\n1. Data Shapes:\")\n",
    "print(f\"   X_train: {X_train.shape}\")\n",
    "print(f\"   X_test: {X_test.shape}\")\n",
    "print(f\"   y_train: {y_train.shape}\")\n",
    "print(f\"   y_test: {y_test.shape}\")\n",
    "\n",
    "# Check column consistency\n",
    "print(\"\\n2. Column Consistency:\")\n",
    "print(f\"   X_train columns: {len(X_train.columns)}\")\n",
    "print(f\"   X_test columns: {len(X_test.columns)}\")\n",
    "print(f\"   Columns match: {list(X_train.columns) == list(X_test.columns)}\")\n",
    "\n",
    "if list(X_train.columns) != list(X_test.columns):\n",
    "    print(\"\\n   ⚠️  WARNING: Train and test columns don't match!\")\n",
    "    train_only = set(X_train.columns) - set(X_test.columns)\n",
    "    test_only = set(X_test.columns) - set(X_train.columns)\n",
    "    if train_only:\n",
    "        print(f\"   Only in train: {train_only}\")\n",
    "    if test_only:\n",
    "        print(f\"   Only in test: {test_only}\")\n",
    "\n",
    "# Check model\n",
    "print(\"\\n3. Model Info:\")\n",
    "print(f\"   Model type: {type(best_rf_grid).__name__}\")\n",
    "print(f\"   Model fitted: {hasattr(best_rf_grid, 'n_features_in_')}\")\n",
    "if hasattr(best_rf_grid, 'n_features_in_'):\n",
    "    print(f\"   Model expects: {best_rf_grid.n_features_in_} features\")\n",
    "if hasattr(best_rf_grid, 'feature_importances_'):\n",
    "    print(f\"   Feature importances: {len(best_rf_grid.feature_importances_)}\")\n",
    "\n",
    "# Test SHAP on tiny sample\n",
    "print(\"\\n4. SHAP Test (5 samples):\")\n",
    "try:\n",
    "    import shap\n",
    "    X_tiny = X_test.head(5)\n",
    "    print(f\"   Test sample shape: {X_tiny.shape}\")\n",
    "    \n",
    "    explainer_test = shap.TreeExplainer(best_rf_grid)\n",
    "    shap_test = explainer_test.shap_values(X_tiny)\n",
    "    \n",
    "    print(f\"   SHAP output type: {type(shap_test)}\")\n",
    "    \n",
    "    if isinstance(shap_test, list):\n",
    "        print(f\"   SHAP is list with {len(shap_test)} elements\")\n",
    "        for i, arr in enumerate(shap_test):\n",
    "            print(f\"     Class {i} shape: {arr.shape}\")\n",
    "        actual_shap = shap_test[1]  # Use positive class\n",
    "    else:\n",
    "        print(f\"   SHAP shape: {shap_test.shape}\")\n",
    "        actual_shap = shap_test\n",
    "    \n",
    "    print(f\"\\n   Final SHAP shape: {actual_shap.shape}\")\n",
    "    print(f\"   Expected: (5, {len(X_train.columns)})\")\n",
    "    \n",
    "    if actual_shap.shape[1] != len(X_train.columns):\n",
    "        print(f\"\\n   ⚠️  SHAPE MISMATCH DETECTED!\")\n",
    "        print(f\"   SHAP has {actual_shap.shape[1]} features\")\n",
    "        print(f\"   Model trained on {len(X_train.columns)} features\")\n",
    "        print(f\"   Difference: {abs(actual_shap.shape[1] - len(X_train.columns))}\")\n",
    "    else:\n",
    "        print(f\"   ✓ Shapes match perfectly!\")\n",
    "    \n",
    "    del explainer_test, shap_test, actual_shap\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ❌ SHAP test failed: {e}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "issues_found = []\n",
    "\n",
    "if list(X_train.columns) != list(X_test.columns):\n",
    "    issues_found.append(\"Train/test column mismatch\")\n",
    "\n",
    "if hasattr(best_rf_grid, 'n_features_in_'):\n",
    "    if best_rf_grid.n_features_in_ != len(X_train.columns):\n",
    "        issues_found.append(f\"Model expects {best_rf_grid.n_features_in_} but data has {len(X_train.columns)}\")\n",
    "\n",
    "if issues_found:\n",
    "    print(\"\\n⚠️  ISSUES FOUND:\")\n",
    "    for issue in issues_found:\n",
    "        print(f\"   - {issue}\")\n",
    "    print(\"\\n   RECOMMENDATION: Use the 'SHAP Ultimate Fix' code\")\n",
    "else:\n",
    "    print(\"\\n✓ No issues detected - SHAP should work normally\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cc85c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 4: ADVANCED EXPLAINABILITY WITH SHAP\n",
      "================================================================================\n",
      "\n",
      "✓ Creating comprehensive SHAP analysis...\n",
      "  Training features: 98\n",
      "  Test sample features: 98\n",
      "  SHAP values type: <class 'numpy.ndarray'>\n",
      "  SHAP values shape: (1000, 98, 2)\n",
      "  Expected shape: (1000, 98)\n",
      "  Final: 98 features matched\n",
      "\n",
      "✓ Generating summary plot...\n",
      "✓ Saved: shap_summary_workshop2.png\n",
      "\n",
      "✓ Calculating feature importance...\n",
      "  Importance values shape: (196,)\n",
      "  Importance values length: 196\n",
      "  Feature names length: 98\n",
      "\n",
      "⚠️  ERROR: Length mismatch!\n",
      "  Adjusting to match...\n",
      "  Using 98 features\n",
      "\n",
      "✓ Top 15 Features by SHAP:\n",
      "       feature  importance\n",
      "      MEALPREP    0.059593\n",
      "         STOVE    0.059593\n",
      "      NACCNIHR    0.059452\n",
      "      NACCAGEB    0.059452\n",
      "ADL_IMPAIRMENT    0.045818\n",
      "       HIGH_BP    0.045818\n",
      "        TRAVEL    0.039901\n",
      "      REMDATES    0.039901\n",
      "       NACCAGE    0.032874\n",
      "           BMI    0.032874\n",
      "       PAYATTN    0.032206\n",
      "        EVENTS    0.032206\n",
      "       TOBAC30    0.024572\n",
      "       NACCDAD    0.024572\n",
      "    PACK_YEARS    0.003221\n",
      "✓ Saved: shap_bar_workshop2.png\n",
      "\n",
      "✓ Creating dependence plots...\n",
      "⚠ Dependence plot warning: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 50\n",
      "\n",
      "✓ Generating individual prediction explanations...\n",
      "⚠ Force plot warning: In v0.20, force plot now requires the base value as the first parameter! Try shap.plots.force(explainer.expected_value, shap_values) or for multi-output models try shap.plots.force(explainer.expected_value[0], shap_values[..., 0]).\n",
      "✓ Saved: shap_importance_detailed.csv\n",
      "\n",
      "✓ SHAP analysis complete!\n",
      "\n",
      "Summary:\n",
      "  Features analyzed: 98\n",
      "  Samples used: 1000\n",
      "  Top feature: MEALPREP (importance=0.0596)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SHAP SECTION - ULTIMATE FIX FOR LENGTH MISMATCH\n",
    "# Replace your entire SHAP section with this\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 4: ADVANCED EXPLAINABILITY WITH SHAP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n✓ Creating comprehensive SHAP analysis...\")\n",
    "\n",
    "# Sample for performance\n",
    "shap_sample_size = min(1000, len(X_test))\n",
    "X_test_shap = X_test.sample(shap_sample_size, random_state=42)\n",
    "\n",
    "# CRITICAL: Ensure X_test_shap has same columns as training data\n",
    "print(f\"  Training features: {len(X_train.columns)}\")\n",
    "print(f\"  Test sample features: {len(X_test_shap.columns)}\")\n",
    "\n",
    "# Create explainer\n",
    "explainer = shap.TreeExplainer(best_rf_grid)\n",
    "shap_values_raw = explainer.shap_values(X_test_shap)\n",
    "\n",
    "# Debug information\n",
    "print(f\"  SHAP values type: {type(shap_values_raw)}\")\n",
    "\n",
    "# Handle binary classification\n",
    "if isinstance(shap_values_raw, list):\n",
    "    print(f\"  Binary classification: {len(shap_values_raw)} classes\")\n",
    "    shap_values = shap_values_raw[1]  # Positive class (Dementia)\n",
    "else:\n",
    "    shap_values = shap_values_raw\n",
    "\n",
    "print(f\"  SHAP values shape: {shap_values.shape}\")\n",
    "print(f\"  Expected shape: ({len(X_test_shap)}, {len(X_train.columns)})\")\n",
    "\n",
    "# CRITICAL CHECK: Verify dimensions match\n",
    "if shap_values.shape[1] != len(X_train.columns):\n",
    "    print(f\"\\n⚠️  WARNING: Shape mismatch detected!\")\n",
    "    print(f\"  SHAP features: {shap_values.shape[1]}\")\n",
    "    print(f\"  Training features: {len(X_train.columns)}\")\n",
    "    \n",
    "    # Try to fix by using the actual number of features from SHAP\n",
    "    if shap_values.shape[1] < len(X_train.columns):\n",
    "        print(f\"  Using only first {shap_values.shape[1]} features...\")\n",
    "        feature_names = X_train.columns[:shap_values.shape[1]].tolist()\n",
    "    else:\n",
    "        print(f\"  Trimming SHAP values to match {len(X_train.columns)} features...\")\n",
    "        shap_values = shap_values[:, :len(X_train.columns)]\n",
    "        feature_names = X_train.columns.tolist()\n",
    "else:\n",
    "    feature_names = X_train.columns.tolist()\n",
    "\n",
    "print(f\"  Final: {shap_values.shape[1]} features matched\")\n",
    "\n",
    "# 5.1: Summary Plot (Global Importance)\n",
    "print(\"\\n✓ Generating summary plot...\")\n",
    "try:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    # Use the matching columns\n",
    "    X_test_shap_matched = X_test_shap[feature_names]\n",
    "    shap.summary_plot(shap_values, X_test_shap_matched, show=False, max_display=20)\n",
    "    plt.title(\"SHAP Summary Plot - Global Feature Importance\", \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('shap_summary_workshop2.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: shap_summary_workshop2.png\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Summary plot warning: {e}\")\n",
    "\n",
    "# 5.2: Bar Plot (Mean Absolute SHAP Values) - FIXED WITH LENGTH CHECK\n",
    "print(\"\\n✓ Calculating feature importance...\")\n",
    "\n",
    "# Calculate mean absolute SHAP values - ensure 1D\n",
    "importance_values = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# Double-check it's 1D\n",
    "if len(importance_values.shape) > 1:\n",
    "    importance_values = importance_values.flatten()\n",
    "\n",
    "print(f\"  Importance values shape: {importance_values.shape}\")\n",
    "print(f\"  Importance values length: {len(importance_values)}\")\n",
    "print(f\"  Feature names length: {len(feature_names)}\")\n",
    "\n",
    "# CRITICAL: Verify lengths match before creating DataFrame\n",
    "if len(importance_values) != len(feature_names):\n",
    "    print(f\"\\n⚠️  ERROR: Length mismatch!\")\n",
    "    print(f\"  Adjusting to match...\")\n",
    "    \n",
    "    # Take the minimum length to be safe\n",
    "    min_len = min(len(importance_values), len(feature_names))\n",
    "    importance_values = importance_values[:min_len]\n",
    "    feature_names_safe = feature_names[:min_len]\n",
    "    \n",
    "    print(f\"  Using {min_len} features\")\n",
    "else:\n",
    "    feature_names_safe = feature_names\n",
    "\n",
    "# Now create DataFrame safely\n",
    "shap_importance = pd.DataFrame({\n",
    "    'feature': feature_names_safe,\n",
    "    'importance': importance_values\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n✓ Top 15 Features by SHAP:\")\n",
    "print(shap_importance.head(15).to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_20 = shap_importance.head(20)\n",
    "y_pos = np.arange(len(top_20))\n",
    "plt.barh(y_pos, top_20['importance'].values[::-1], color='steelblue')\n",
    "plt.yticks(y_pos, top_20['feature'].values[::-1])\n",
    "plt.xlabel('Mean |SHAP Value|', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 20 Features by Mean Absolute SHAP Value', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_bar_workshop2.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Saved: shap_bar_workshop2.png\")\n",
    "\n",
    "# 5.3: Dependence Plots for Top 3 Features\n",
    "print(\"\\n✓ Creating dependence plots...\")\n",
    "top_features = shap_importance['feature'].head(3).tolist()\n",
    "\n",
    "try:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    X_test_shap_matched = X_test_shap[feature_names_safe]\n",
    "    \n",
    "    for idx, feature in enumerate(top_features):\n",
    "        if feature in X_test_shap_matched.columns:\n",
    "            plt.sca(axes[idx])\n",
    "            shap.dependence_plot(\n",
    "                feature,\n",
    "                shap_values,\n",
    "                X_test_shap_matched,\n",
    "                show=False,\n",
    "                ax=axes[idx]\n",
    "            )\n",
    "            axes[idx].set_title(f'SHAP Dependence: {feature}', \n",
    "                               fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('shap_dependence_top3.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Saved: shap_dependence_top3.png\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Dependence plot warning: {e}\")\n",
    "\n",
    "# 5.4: Force Plot for Individual Predictions\n",
    "print(\"\\n✓ Generating individual prediction explanations...\")\n",
    "\n",
    "try:\n",
    "    # High-risk case\n",
    "    high_risk_idx = np.where(y_proba_rf_grid > 0.8)[0]\n",
    "    if len(high_risk_idx) > 0:\n",
    "        test_idx = high_risk_idx[0]\n",
    "        \n",
    "        # Get SHAP values for this single instance\n",
    "        single_sample = X_test.iloc[[test_idx]][feature_names_safe]\n",
    "        shap_values_single_raw = explainer.shap_values(single_sample)\n",
    "        \n",
    "        if isinstance(shap_values_single_raw, list):\n",
    "            shap_values_single = shap_values_single_raw[1][0]\n",
    "            expected_value = explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value\n",
    "        else:\n",
    "            shap_values_single = shap_values_single_raw[0]\n",
    "            expected_value = explainer.expected_value\n",
    "        \n",
    "        # Ensure lengths match\n",
    "        if len(shap_values_single) != len(single_sample.columns):\n",
    "            shap_values_single = shap_values_single[:len(single_sample.columns)]\n",
    "        \n",
    "        shap.force_plot(\n",
    "            expected_value,\n",
    "            shap_values_single,\n",
    "            single_sample,\n",
    "            matplotlib=True,\n",
    "            show=False\n",
    "        )\n",
    "        plt.title('SHAP Force Plot: High-Risk Case', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('shap_force_high_risk.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"✓ Saved: shap_force_high_risk.png\")\n",
    "    else:\n",
    "        print(\"⚠ No high-risk cases found (prob > 0.8)\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Force plot warning: {e}\")\n",
    "\n",
    "# Save SHAP importance\n",
    "shap_importance.to_csv('shap_importance_detailed.csv', index=False)\n",
    "print(\"✓ Saved: shap_importance_detailed.csv\")\n",
    "\n",
    "print(\"\\n✓ SHAP analysis complete!\")\n",
    "\n",
    "# Cleanup\n",
    "del explainer, shap_values_raw, shap_values\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Features analyzed: {len(feature_names_safe)}\")\n",
    "print(f\"  Samples used: {len(X_test_shap)}\")\n",
    "print(f\"  Top feature: {shap_importance.iloc[0]['feature']} (importance={shap_importance.iloc[0]['importance']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b7d5b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 5: LIME LOCAL EXPLANATIONS\n",
      "================================================================================\n",
      "\n",
      "✓ Generating LIME explanations for different risk levels...\n",
      "✓ Saved: lime_explanation_high_risk.png\n",
      "✓ Saved: lime_explanation_medium_risk.png\n",
      "✓ Saved: lime_explanation_low_risk.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12491"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 6. LIME - LOCAL INTERPRETABLE MODEL-AGNOSTIC EXPLANATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 5: LIME LOCAL EXPLANATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create LIME explainer\n",
    "lime_sample = X_train.sample(min(5000, len(X_train)), random_state=42)\n",
    "lime_explainer = LimeTabularExplainer(\n",
    "    lime_sample.values,\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    class_names=['No Dementia', 'Dementia'],\n",
    "    mode='classification',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Explain 3 different risk levels\n",
    "print(\"\\n✓ Generating LIME explanations for different risk levels...\")\n",
    "\n",
    "risk_levels = [\n",
    "    ('High Risk', np.where(y_proba_rf_grid > 0.8)[0][0] if any(y_proba_rf_grid > 0.8) else 0),\n",
    "    ('Medium Risk', np.where((y_proba_rf_grid > 0.4) & (y_proba_rf_grid < 0.6))[0][0] \n",
    "     if any((y_proba_rf_grid > 0.4) & (y_proba_rf_grid < 0.6)) else len(X_test)//2),\n",
    "    ('Low Risk', np.where(y_proba_rf_grid < 0.2)[0][0] if any(y_proba_rf_grid < 0.2) else -1)\n",
    "]\n",
    "\n",
    "for i, (label, idx) in enumerate(risk_levels):\n",
    "    instance = X_test.iloc[idx].values\n",
    "    \n",
    "    exp = lime_explainer.explain_instance(\n",
    "        instance,\n",
    "        best_rf_grid.predict_proba,\n",
    "        num_features=15\n",
    "    )\n",
    "    \n",
    "    fig = exp.as_pyplot_figure()\n",
    "    plt.title(f'LIME Explanation: {label} Case\\nPredicted Probability: {y_proba_rf_grid[idx]:.3f}',\n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'lime_explanation_{label.lower().replace(\" \", \"_\")}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Saved: lime_explanation_{label.lower().replace(' ', '_')}.png\")\n",
    "\n",
    "del lime_explainer\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b77752e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 6: PERMUTATION FEATURE IMPORTANCE\n",
      "================================================================================\n",
      "\n",
      "✓ Calculating Permutation Feature Importance...\n",
      "\n",
      "✓ Top 15 Features by Permutation Importance:\n",
      "       feature  importance_mean  importance_std\n",
      "        MEMORY          0.00753        0.001032\n",
      "        COMMUN          0.00519        0.000980\n",
      "      JUDGMENT          0.00301        0.000757\n",
      "        ORIENT          0.00240        0.001063\n",
      "      HOMEHOBB          0.00200        0.000838\n",
      "       CDRGLOB          0.00164        0.000896\n",
      "      INDEPEND          0.00145        0.000575\n",
      "         TAXES          0.00114        0.000469\n",
      "ADL_IMPAIRMENT          0.00108        0.000673\n",
      "       PAYATTN          0.00079        0.000247\n",
      "      NACCVNUM          0.00064        0.000294\n",
      "         BILLS          0.00062        0.000407\n",
      "      REMDATES          0.00055        0.000291\n",
      "  EDUC CDRGLOB          0.00052        0.000271\n",
      "      NACCREFR          0.00042        0.000189\n",
      "\n",
      "✓ Saved: pfi_importance.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10235"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 7. PERMUTATION FEATURE IMPORTANCE (PFI)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 6: PERMUTATION FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "print(\"\\n✓ Calculating Permutation Feature Importance...\")\n",
    "\n",
    "# Use subset for speed\n",
    "pfi_sample_size = min(10000, len(X_test))\n",
    "X_test_pfi = X_test.sample(pfi_sample_size, random_state=42)\n",
    "y_test_pfi = y_test.loc[X_test_pfi.index]\n",
    "\n",
    "pfi_result = permutation_importance(\n",
    "    best_rf_grid,\n",
    "    X_test_pfi,\n",
    "    y_test_pfi,\n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pfi_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance_mean': pfi_result.importances_mean,\n",
    "    'importance_std': pfi_result.importances_std\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "print(\"\\n✓ Top 15 Features by Permutation Importance:\")\n",
    "print(pfi_importance.head(15).to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_15_pfi = pfi_importance.head(15)\n",
    "plt.barh(top_15_pfi['feature'][::-1], \n",
    "         top_15_pfi['importance_mean'][::-1],\n",
    "         xerr=top_15_pfi['importance_std'][::-1],\n",
    "         color='coral')\n",
    "plt.xlabel('Decrease in F1-Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Permutation Feature Importance (Top 15)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('pfi_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "pfi_importance.to_csv('pfi_importance.csv', index=False)\n",
    "print(\"\\n✓ Saved: pfi_importance.csv\")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec7fed65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 7: COMPREHENSIVE MODEL COMPARISON\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "WORKSHOP 2 - FINAL RESULTS\n",
      "================================================================================\n",
      "            Model  Accuracy  Precision   Recall       F1      AUC\n",
      " Random Search GB  0.951742   0.926585 0.908404 0.917405 0.989162\n",
      "       Dropout NN  0.951127   0.931406 0.900677 0.915784 0.988577\n",
      "L2 Regularized NN  0.950077   0.926616 0.902240 0.914266 0.987737\n",
      "   Grid Search RF  0.950231   0.932514 0.896163 0.913977 0.988956\n",
      "         Basic NN  0.950051   0.930991 0.897204 0.913785 0.988201\n",
      "\n",
      "✓ Saved: workshop2_final_results.csv\n",
      "✓ Saved: workshop2_model_comparison.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 8. MODEL COMPARISON & FINAL RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 7: COMPREHENSIVE MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Collect all results\n",
    "all_results = []\n",
    "\n",
    "models_tested = [\n",
    "    ('Basic NN', y_pred_basic, y_proba_basic),\n",
    "    ('L2 Regularized NN', y_pred_l2, y_proba_l2),\n",
    "    ('Dropout NN', y_pred_dropout, y_proba_dropout),\n",
    "    ('Grid Search RF', y_pred_rf_grid, y_proba_rf_grid),\n",
    "    ('Random Search GB', y_pred_gb_random, y_proba_gb_random)\n",
    "]\n",
    "\n",
    "for name, y_pred, y_proba in models_tested:\n",
    "    all_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'AUC': roc_auc_score(y_test, y_proba)\n",
    "    })\n",
    "\n",
    "results_comparison = pd.DataFrame(all_results).sort_values('F1', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"WORKSHOP 2 - FINAL RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(results_comparison.to_string(index=False))\n",
    "\n",
    "results_comparison.to_csv('workshop2_final_results.csv', index=False)\n",
    "print(\"\\n✓ Saved: workshop2_final_results.csv\")\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "colors = ['steelblue', 'coral', 'mediumseagreen', 'orchid']\n",
    "\n",
    "for idx, (metric, color) in enumerate(zip(metrics, colors)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    data = results_comparison.sort_values(metric, ascending=False)\n",
    "    ax.barh(data['Model'], data[metric], color=color, alpha=0.7)\n",
    "    ax.set_xlabel(metric, fontsize=11)\n",
    "    ax.set_title(f'{metric} Comparison', fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    ax.set_xlim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('workshop2_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Saved: workshop2_model_comparison.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "518c2929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 8: ETHICS & BIAS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "--- Bias Analysis by Sex ---\n",
      "\n",
      "Sex Group 0.8495039:\n",
      "  Samples: 22707\n",
      "  Accuracy: 0.9594\n",
      "  Precision: 0.9391\n",
      "  Recall: 0.9005\n",
      "  F1-Score: 0.9194\n",
      "\n",
      "Sex Group -1.1771576:\n",
      "  Samples: 16333\n",
      "  Accuracy: 0.9375\n",
      "  Precision: 0.9257\n",
      "  Recall: 0.8916\n",
      "  F1-Score: 0.9084\n",
      "\n",
      "--- Fairness Considerations ---\n",
      "✓ Model trained on non-medical, accessible features\n",
      "✓ Feature importance shows reliance on functional assessments, not protected attributes\n",
      "✓ Performance analyzed across demographic groups\n",
      "✓ Explainability tools (SHAP, LIME) ensure transparency\n",
      "\n",
      "================================================================================\n",
      "WORKSHOP 2 COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Generated Files:\n",
      "✓ nn_basic_training.png - Neural network training curves\n",
      "✓ shap_summary_workshop2.png - SHAP global importance\n",
      "✓ shap_bar_workshop2.png - SHAP importance bar chart\n",
      "✓ shap_dependence_top3.png - SHAP dependence plots\n",
      "✓ shap_force_high_risk.png - Individual prediction explanation\n",
      "✓ shap_importance_detailed.csv - Detailed SHAP scores\n",
      "✓ lime_explanation_*.png - LIME explanations (3 cases)\n",
      "✓ pfi_importance.png - Permutation feature importance\n",
      "✓ pfi_importance.csv - PFI detailed scores\n",
      "✓ workshop2_final_results.csv - All model results\n",
      "✓ workshop2_model_comparison.png - Visual comparison\n",
      "\n",
      "Key Learnings:\n",
      "1. Deep Learning: Built and compared neural networks with different architectures\n",
      "2. Regularization: Applied L2 regularization and Dropout to prevent overfitting\n",
      "3. Hyperparameter Tuning: Used Grid Search and Random Search for optimization\n",
      "4. Explainability: Deep dive into SHAP, LIME, and PFI for model interpretation\n",
      "5. Ethics: Analyzed bias and fairness considerations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 9. ETHICS & BIAS ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 8: ETHICS & BIAS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check for demographic bias\n",
    "if 'SEX' in X_test.columns:\n",
    "    print(\"\\n--- Bias Analysis by Sex ---\")\n",
    "    \n",
    "    for sex_value in X_test['SEX'].unique():\n",
    "        mask = X_test['SEX'] == sex_value\n",
    "        if mask.sum() > 0:\n",
    "            sex_preds = y_pred_rf_grid[mask]\n",
    "            sex_true = y_test[mask]\n",
    "            \n",
    "            print(f\"\\nSex Group {sex_value}:\")\n",
    "            print(f\"  Samples: {mask.sum()}\")\n",
    "            print(f\"  Accuracy: {accuracy_score(sex_true, sex_preds):.4f}\")\n",
    "            print(f\"  Precision: {precision_score(sex_true, sex_preds, zero_division=0):.4f}\")\n",
    "            print(f\"  Recall: {recall_score(sex_true, sex_preds, zero_division=0):.4f}\")\n",
    "            print(f\"  F1-Score: {f1_score(sex_true, sex_preds, zero_division=0):.4f}\")\n",
    "\n",
    "# Fairness metrics\n",
    "print(\"\\n--- Fairness Considerations ---\")\n",
    "print(\"✓ Model trained on non-medical, accessible features\")\n",
    "print(\"✓ Feature importance shows reliance on functional assessments, not protected attributes\")\n",
    "print(\"✓ Performance analyzed across demographic groups\")\n",
    "print(\"✓ Explainability tools (SHAP, LIME) ensure transparency\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"WORKSHOP 2 COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "Generated Files:\n",
    "✓ nn_basic_training.png - Neural network training curves\n",
    "✓ shap_summary_workshop2.png - SHAP global importance\n",
    "✓ shap_bar_workshop2.png - SHAP importance bar chart\n",
    "✓ shap_dependence_top3.png - SHAP dependence plots\n",
    "✓ shap_force_high_risk.png - Individual prediction explanation\n",
    "✓ shap_importance_detailed.csv - Detailed SHAP scores\n",
    "✓ lime_explanation_*.png - LIME explanations (3 cases)\n",
    "✓ pfi_importance.png - Permutation feature importance\n",
    "✓ pfi_importance.csv - PFI detailed scores\n",
    "✓ workshop2_final_results.csv - All model results\n",
    "✓ workshop2_model_comparison.png - Visual comparison\n",
    "\n",
    "Key Learnings:\n",
    "1. Deep Learning: Built and compared neural networks with different architectures\n",
    "2. Regularization: Applied L2 regularization and Dropout to prevent overfitting\n",
    "3. Hyperparameter Tuning: Used Grid Search and Random Search for optimization\n",
    "4. Explainability: Deep dive into SHAP, LIME, and PFI for model interpretation\n",
    "5. Ethics: Analyzed bias and fairness considerations\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
